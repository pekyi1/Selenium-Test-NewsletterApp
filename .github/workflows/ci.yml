name: CI - Selenium UI Tests

on:
  push:
  pull_request:

jobs:
  ui-tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Java 17
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"
          cache: maven

      - name: Print target URL
        run: |
          echo "Testing URL: ${{ secrets.APP_BASE_URL }}"

      - name: Run Selenium tests (headless)
        run: mvn -B -e test -Dheadless=true -DbaseUrl=${{ secrets.APP_BASE_URL }} -DtrimStackTrace=false

      # Human-friendly summary in GitHub Actions logs (non-technical)
      - name: Human-friendly test summary (readable)
        if: always()
        run: |
          python3 - <<'PY'
          import glob, xml.etree.ElementTree as ET, os

          files = sorted(glob.glob("target/surefire-reports/TEST-*.xml"))
          if not files:
              print("No Surefire XML reports found (target/surefire-reports/TEST-*.xml).")
              raise SystemExit(0)

          total_tests = total_failures = total_errors = total_skipped = 0
          failed_details = []

          for f in files:
              root = ET.parse(f).getroot()
              suite_name = root.attrib.get("name", os.path.basename(f))
              tests = int(root.attrib.get("tests", 0))
              failures = int(root.attrib.get("failures", 0))
              errors = int(root.attrib.get("errors", 0))
              skipped = int(root.attrib.get("skipped", 0))

              total_tests += tests
              total_failures += failures
              total_errors += errors
              total_skipped += skipped

              for tc in root.findall("testcase"):
                  tname = tc.attrib.get("name", "(unnamed test)")
                  cname = tc.attrib.get("classname", suite_name)

                  failure = tc.find("failure")
                  error = tc.find("error")

                  if failure is not None:
                      msg = (failure.attrib.get("message") or "A check did not match the expected result.").strip()
                      failed_details.append(("FAIL", cname, tname, msg))
                  elif error is not None:
                      msg = (error.attrib.get("message") or "The test could not complete.").strip()
                      failed_details.append(("ERROR", cname, tname, msg))

          passed = total_tests - total_failures - total_errors - total_skipped

          print("\n==============================")
          print("SELENIUM UI TEST SUMMARY (Readable)")
          print("==============================")
          print(f"Total tests : {total_tests}")
          print(f"Passed      : {passed}")
          print(f"Failed      : {total_failures}")
          print(f"Errors      : {total_errors}")
          print(f"Skipped     : {total_skipped}")

          if failed_details:
              print("\nWhat failed and why")
              print("-------------------")
              for status, cls, name, msg in failed_details:
                  clean = " ".join(msg.replace("\\n", " ").split())
                  print(f"- {name} ({status})")
                  print(f"  Reason: {clean}")
          else:
              print("\nAll tests passed ✅")

          print("==============================\n")
          PY

      # Build Slack-friendly summary (non-technical)
      - name: Build Slack payload (non-technical, detailed)
        if: always()
        run: |
          python3 - <<'PY'
          import glob, xml.etree.ElementTree as ET, json

          files = sorted(glob.glob("target/surefire-reports/TEST-*.xml"))

          total_tests = total_failures = total_errors = total_skipped = 0
          passed_tests = []
          failed_tests = []  # (name, reason)
          error_tests = []   # (name, reason)

          for f in files:
              root = ET.parse(f).getroot()
              total_tests += int(root.attrib.get("tests", 0))
              total_failures += int(root.attrib.get("failures", 0))
              total_errors += int(root.attrib.get("errors", 0))
              total_skipped += int(root.attrib.get("skipped", 0))

              for tc in root.findall("testcase"):
                  name = tc.attrib.get("name", "(unnamed test)")
                  failure = tc.find("failure")
                  error = tc.find("error")

                  if failure is not None:
                      msg = (failure.attrib.get("message") or "The app did not behave as expected.").strip()
                      failed_tests.append((name, " ".join(msg.split())))
                  elif error is not None:
                      msg = (error.attrib.get("message") or "The test could not complete.").strip()
                      error_tests.append((name, " ".join(msg.split())))
                  else:
                      passed_tests.append(name)

          passed_count = total_tests - total_failures - total_errors - total_skipped
          status = "PASSED ✅" if (total_failures + total_errors) == 0 else "FAILED ❌"

          # Slack has message length limits — keep it readable and capped
          MAX_PASSED_TO_SHOW = 8
          MAX_FAILED_TO_SHOW = 8

          lines = []
          lines.append(f"*Selenium UI Tests {status}*")
          lines.append(f"Total: {total_tests} | Passed: {passed_count} | Failed: {total_failures} | Errors: {total_errors} | Skipped: {total_skipped}")
          lines.append("")

          if passed_tests:
              lines.append("*Passed checks*")
              for t in passed_tests[:MAX_PASSED_TO_SHOW]:
                  lines.append(f"• {t}")
              if len(passed_tests) > MAX_PASSED_TO_SHOW:
                  lines.append(f"• …and {len(passed_tests) - MAX_PASSED_TO_SHOW} more passed")
              lines.append("")

          if failed_tests or error_tests:
              lines.append("*What failed and why*")
              for (t, reason) in failed_tests[:MAX_FAILED_TO_SHOW]:
                  lines.append(f"• {t} — {reason}")
              for (t, reason) in error_tests[:MAX_FAILED_TO_SHOW]:
                  lines.append(f"• {t} — {reason}")
              extra = (len(failed_tests) - min(len(failed_tests), MAX_FAILED_TO_SHOW)) + (len(error_tests) - min(len(error_tests), MAX_FAILED_TO_SHOW))
              if extra > 0:
                  lines.append(f"• …and {extra} more failures/errors (see workflow run for full details)")
              lines.append("")

          # Always include run link
          # GitHub will fill these via env vars in the workflow step
          run_link = "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          lines.append(f"Run details: {run_link}")

          payload = {"text": "\n".join(lines)}

          with open("slack_payload.json", "w", encoding="utf-8") as f:
              json.dump(payload, f)
          PY

      - name: Notify Slack (detailed non-technical report)
        if: always()
        uses: slackapi/slack-github-action@v1.27.0
        with:
          payload-file-path: slack_payload.json
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}


      # Technical reports for evidence (prints only when failing)
      - name: Print Surefire reports (on failure)
        if: failure()
        run: |
          echo "=== Surefire Reports Directory ==="
          ls -la target/surefire-reports || true

          echo "=== Dumping Surefire .txt reports (test failures/errors) ==="
          for f in target/surefire-reports/*.txt; do
            if [ -f "$f" ]; then
              echo "----- $f -----"
              cat "$f"
              echo
            fi
          done

      - name: Upload Surefire test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: surefire-reports
          path: target/surefire-reports/**

      # Upload Selenium failure evidence (only exists if your tests write to target/test-evidence)
      - name: Upload UI failure evidence
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ui-test-evidence
          path: target/test-evidence/**

      - name: Notify Slack (non-technical summary)
        if: always()
        uses: slackapi/slack-github-action@v1.27.0
        with:
          payload: |
            {
              "text": "${{ steps.slack_summary.outputs.message }}\n\nRepo: `${{ github.repository }}` | Branch: `${{ github.ref_name }}`\nRun details: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
